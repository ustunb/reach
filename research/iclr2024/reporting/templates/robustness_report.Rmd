---
output:
  pdf_document:  # see https://bookdown.org/yihui/rmarkdown/pdf-document.html for complete list
    keep_tex: yes
    fig_width: 7
    fig_height: 5
    fig_caption: true
    toc: false
    number_sections: false
    extra_dependencies: # use this to load latex packages with options
      grffile: ["space"] # e.g., this is the same as \usepackage[space]{grrfile}
      flafter: []
      booktabs: []
      placeins: []
      graphicx: []

fontsize: 11pt
geometry: margin=1in

params:
    venv_dir: '/Users/avnikothari/.virtualenvs/reticulate-python-env/bin/python3'
    report_data: '/Users/avnikothari/Desktop/UCSD/Research/infeasible-recourse/results/german_action_set_1.results' # path to the pickle file for this template
    report_python_dir: '/Users/avnikothari/Desktop/UCSD/Research/infeasible-recourse/' # directory containing python code
    build_dir: '/Users/avnikothari/Desktop/UCSD/Research/infeasible-recourse/reports/' # directory where the template will be compiled
---

```{r setup-r, include = FALSE}
# Use this chunk to default options for how to evaluate each code chunk in the template
# For a complete list of options, see: https://yihui.org/knitr/options/#package_options
knitr::opts_knit$set(
  echo = FALSE, # set to TRUE to print code in the final report?
  include = FALSE,
  fig.path = '/Users/avnikothari/Desktop/UCSD/Research/infeasible-recourse/figure/' # pass the path for where to store PDFs
  )


# load R packages
packages = c('reticulate', 'tidyverse', 'xtable', 'stringr', 'ggplot2', 'tinytex')
for (pkg in packages) {
  library(pkg, character.only = TRUE, warn.conflicts = FALSE, quietly = TRUE, verbose = FALSE)
}

# load reticulate virtual environment
# load python virtual environment for reticulate
tryCatch({
  use_condaenv(condaenv = params$venv_dir, required = FALSE)
}, error = function(error_condition) {
  use_virtualenv(virtualenv = params$venv_dir, required = TRUE)
})

```

```{python setup-python, include = FALSE}
# Use this chunk to set up your Python environment

import os
import sys
print(os.getcwd())

sys.path.append(r.params['report_python_dir'])

from src.paths import *
from src.ext import fileutils
import pandas as pd
import numpy as np
from datetime import datetime


```

```{=latex}
% Use this chunk to define Tex functions and run Tex commands
% Whatever you put here will be placed after "\begin{document}" so you can't import packages
% To import Tex packages just list them after `extra_dependencies`

\newcommand{\cell}[2]{\begin{tabular}{#1}#2\end{tabular}}
\pagenumbering{gobble}
```



```{python, include = FALSE}
##### REPORT DATA AND CONSTANTS ########

# settings = {
#     'data_name': 'fico',
#     'random_seed': 2338,
#     'action_set_name': 'action_set_9',
#     'fold_id':'K05N01',
#     'description': ''
#     }

settings = fileutils.load(get_report_metadata_file())

FOLD_ID = settings['fold_id']

OUTCOME_PROB = 1

data_name = settings['data_name']
random_seed = settings['random_seed']
action_set_name = settings['action_set_name']
```

```{python, include = FALSE}
# load the report data from Python
processed_data = fileutils.load(get_data_file(data_name, action_set_name))
raw_data = fileutils.load(get_raw_data_file(data_name))
action_set = fileutils.load(get_action_set_file(data_name, action_set_name))
results = fileutils.load(get_audit_results_file(data_name, action_set_name))

# models data
raw_log_reg = fileutils.load(get_model_file(data_name, action_set_name, 'log_reg', is_raw = True))
processed_log_reg =  fileutils.load(get_model_file(data_name, action_set_name, 'log_reg', is_raw = False))
raw_rf_sklearn = fileutils.load(get_model_file(data_name, action_set_name, 'rf_sklearn', is_raw = True))
processed_rf_sklearn = fileutils.load(get_model_file(data_name, action_set_name, 'rf_sklearn', is_raw = False))
raw_xgb = fileutils.load(get_model_file(data_name, action_set_name, 'xgb', is_raw = True))
processed_xgb = fileutils.load(get_model_file(data_name, action_set_name, 'xgb', is_raw = False))

rs_df = pd.DataFrame(data=results["reachable_sets"])
fp_df = pd.DataFrame(data=results["fixed_points"])
```


```{r, include=FALSE}
######## HELPER R FUNCTIONS #############
latex_bold <- function(x) {
                        x <- paste0('{\\bfseries ', x, '}')
                        x <- gsub(fixed = TRUE, pattern = "_", replacement = "\\_",x= x)
                        return(x)
                        }
```

```{python, include=FALSE}
######## HELPER PYTHON FUNCTIONS #############
def presenter_df(df):
  df = df.applymap(str)
  return df.replace("<NA>", pd.NA)

def get_proto_strings(val, variable_types, is_action = False):
  new_val = []
  for (val, var_type) in zip(val, variable_types):
      if pd.isna(val):
          new_val.append(pd.NA)
      elif var_type == bool and val == 1:
          new_val.append("1")
      elif (var_type == int or var_type == bool) and val == 0:
        if is_action:
          new_val.append(pd.NA)
        else:
          new_val.append("0")
      elif var_type == bool and val == -1:
          new_val.append("-1")
      else:
          new_val.append(val)
  return new_val

def as_prototype_dict_action(x_val, action_val, action_set_df):
    A_df = action_set_df.sort_values(by=['actionable'])
    features = action_set_df["name"].tolist()
    variable_types = action_set_df["variable_type"].tolist()
    new_x_val = np.add(x_val, action_val)
    
    action_val = [pd.NA if action_val[i] == x_val[i] else action_val[i] for i in range(len(action_val))]
    new_action_val = get_proto_strings(action_val, variable_types, is_action=True)
            
    proto = {"id_for_x": pd.NA}
    for (feat, new_val) in zip(features, new_action_val):
        proto[feat] = new_val
    
    proto["y"] = pd.NA
    predictions_for_proto(proto, new_x_val)
    return proto
  
def predictions_for_proto(proto, val):
  lr_pred = find_model.probs(processed_log_reg['model'], val, OUTCOME_PROB, scaler=processed_log_reg['scaler'])
  rf_pred = find_model.predict(processed_rf_sklearn['model'], val)
  xgb_pred = find_model.predict(processed_xgb['model'], val)
    
  
  proto["LR_pred"] = lr_pred
  proto["RF_sklearn_pred"] = rf_pred
  proto["XGB_pred"] = xgb_pred
  return proto
  
  
def as_prototype_dict_x(id_for_x, datapoint, action_set_df):
    A_df = action_set_df.sort_values(by=['actionable'])
    features = action_set_df["name"].tolist()
    variable_types = action_set_df["variable_type"].tolist()   
    new_datapoint = get_proto_strings(datapoint, variable_types)
          
    proto = {"id_for_x": id_for_x}
    for (feat, new_val) in zip(features, new_datapoint):
        proto[feat] = new_val

    y_true = processed_data.y[id_for_x]
    proto["y"] = y_true
    proto = predictions_for_proto(proto, datapoint)
    return proto
```



```{python, include = FALSE}
######## REPORT DATA TABLE #############
info = {
    'Data Name': data_name,
    'Action Set Name': action_set_name,
    'Fold Id': FOLD_ID,
    'Report Creation Date': datetime.now().strftime("%b-%d-%Y"),
    'n': processed_data.n,
    'd': processed_data.d,
    'y_name': processed_data.names.y,
    'Predicted Outcome Prob': "+1" if OUTCOME_PROB == 1 else "-1",
    'description': settings['description']
}

info_df = pd.DataFrame.from_records([info]).transpose()
```

```{r, include=FALSE}
######## REPORT DATA TABLE #############
xt = xtable(py$info_df, align = c("l", "r"))

n_rows = nrow(py$info_df)
xt_str = print.xtable(xt,
                      type = "latex", 
                      tabular.environment = "tabular",
                      booktabs = TRUE,
                      floating = FALSE,
                      include.rownames = TRUE,
                      include.colnames = FALSE,
                      NA.string="-",
                      comment=FALSE,
                      timestamp=FALSE,
                      hline.after=NULL,
                      add.to.row = list(pos=as.list(-1:n_rows), command=c('\\toprule ','',rep('\\midrule ',n_rows-1),'\\bottomrule\n')),
                      sanitize.rownames.function = function(x) latex_bold(x),
                      );
```

\begin{table}[h]
\small
`r xt_str`
\end{table}

```{python, include = FALSE}
######## ACTION SET TABLE #############
def get_var_type(var_type):
    if var_type == bool:
        return 'bool'
    elif var_type == int:
        return 'int'
    elif var_type == float:
        return 'float'
    else:
        return None
  
# changes variables in dataframe for presentation format    
A_df = action_set.df
A_df["var_type"] = A_df.apply(lambda row: get_var_type(row["variable_type"]), axis =1)
A_df["actionable"] = A_df.apply(lambda row: 'T' if row["actionable"] == True else 'F', axis =1)
A_df = A_df.rename(columns={"step_direction": "step_dir"})

def get_reachable_group_type(row):
  if row['additional_constraint'] == "reachable_group":
    num_ones = np.count_nonzero(row['info']['point_set'][0] == 1)
    if num_ones > 1:
      return "thermometer_one_hot"
    else:
      return "one_hot_ordinal"
  elif row['additional_constraint'] == "if_then":
    return "if_then"
  else:
    return pd.NA
    

# Get additional constraints on features
# Merge interactions and constraints
constraints_join_df = pd.merge(action_set.interactions.info_df, action_set.interactions.feature_df, left_index=True, right_on= 'constraint_id')
# Join constraints with Action Set
features_and_constraints_df = pd.merge(A_df, constraints_join_df, how='left', left_index=True, right_on='feature_idx')

# change column names for presentation format
features_and_constraints_df = features_and_constraints_df.rename(columns={"type": "additional_constraint"})
features_and_constraints_df["additional_constraint"] = features_and_constraints_df.apply(lambda row: get_reachable_group_type(row), axis=1)
A_display_df = features_and_constraints_df[["name", "var_type", "actionable", "step_dir", "additional_constraint"]]
A_display_df = A_display_df.drop_duplicates(subset=['name'])

# for presentation
def update_step_dir(step_dir):
  if step_dir > 0:
    return "+"
  elif step_dir < 0:
    return "-"
  else:
    return step_dir

A_display_df["step_dir"] = A_display_df.apply(lambda row: update_step_dir(row["step_dir"]), axis=1)
A_display_df = A_display_df.reset_index(drop=True)
A_display_df = presenter_df(A_display_df)
```


```{r, include = FALSE}
######## ACTION SET TABLE #############
xt = xtable(py$A_display_df, align = c("l", "l", "l", "l", "l", "r"))

n_rows = nrow(py$A_display_df)
xt_str_act = print.xtable(xt,
                      type = "latex", 
                      tabular.environment = "tabular",
                      booktabs = TRUE,
                      floating = FALSE,
                      include.rownames = FALSE,
                      include.colnames = TRUE,
                      NA.string="-",
                      comment=FALSE,
                      timestamp=FALSE,
                      add.to.row = list(pos=as.list(-1:n_rows), command=c('\\toprule ','',rep('\\midrule ',n_rows-1),'\\bottomrule\n')),
                      sanitize.colnames.function = function(x) latex_bold(x),
                      file="~/Desktop/fico_action_set.tex"
                      );
```
\section{Action Set Description}
\begin{table}[h]
\fontsize{9pt}{9pt}\selectfont
`r xt_str_act`
\end{table}
\FloatBarrier
\clearpage

```{python, include = FALSE}
######## LOG REG MODEL TABLE ############
def log_reg_stats(raw_data_log_reg, processed_data_log_reg):
    train_raw = raw_data_log_reg["train"]
    test_raw = raw_data_log_reg["test"]
    
    train_processed = processed_data_log_reg["train"]
    test_processed = processed_data_log_reg["test"]
    
    return pd.DataFrame(data=[
    ["raw", "log loss", train_raw["log_loss"],  test_raw["log_loss"]],
    ["raw", "auc", train_raw["auc"],  test_raw["auc"]],
    ["raw", "error", train_raw["error"],  test_raw["error"]], 
    ["raw", "ece", train_raw["ece"], test_raw["ece"]],
    ["processed", "log loss", train_processed["log_loss"],  test_processed["log_loss"]],
    ["processed", "auc", train_processed["auc"],  test_processed["auc"]],
    ["processed", "error", train_processed["error"],  test_processed["error"]], 
    ["processed", "ece", train_processed["ece"], test_processed["ece"]],
    ], columns=["Dataset Type", "Metric Name", "Value on Training Set", "Value on Test Set"])
    
log_reg_model_stats_df = presenter_df(log_reg_stats(raw_log_reg, processed_log_reg))
```

```{r, include = FALSE}
######## LOG REG MODEL TABLE #############
xt = xtable(py$log_reg_model_stats_df, align = c("l", "l", "l", "l", "l"))

n_rows = nrow(py$log_reg_model_stats_df)
xt_str_log_reg_model_stats = print.xtable(xt,
                      type = "latex", 
                      tabular.environment = "tabular",
                      booktabs = TRUE,
                      floating = FALSE,
                      include.rownames = FALSE,
                      include.colnames = TRUE,
                      NA.string="-",
                      comment=FALSE,
                      timestamp=FALSE,
                      add.to.row = list(pos=as.list(-1:n_rows), command=c('\\toprule ','',rep('\\midrule ',n_rows-1),'\\bottomrule\n')),
                      sanitize.colnames.function = function(x) latex_bold(x)
                      );
```
\section{Logistic Regression Model}
\begin{table}[h]
\small
`r xt_str_log_reg_model_stats`
\end{table}

\FloatBarrier


```{python, include = FALSE}
######## RANDOM FOREST SKLEARN MODEL TABLE #############
def rf_stats(raw_data_rf, processed_data_rf):
    train_raw = raw_data_rf["train"]
    test_raw = raw_data_rf["test"]

    train_processed = processed_data_rf["train"]
    test_processed = processed_data_rf["test"]

    return pd.DataFrame(data=[
    ["raw", "auc", train_raw["auc"],  test_raw["auc"]],
    ["raw", "error", train_raw["error"],  test_raw["error"]],
    ["processed", "auc", train_processed["auc"],  test_processed["auc"]],
    ["processed", "error", train_processed["error"],  test_processed["error"]],
    ], columns=["Dataset Type", "Metric Name", "Value on Training Set", "Value on Test Set"])

raw_rf_model_stats_df = presenter_df(rf_stats(raw_rf_sklearn, processed_rf_sklearn))
```


```{r, include=FALSE}
######## RANDOM FOREST RAW MODEL DATA TABLE #############
xt = xtable(py$raw_rf_model_stats_df, align = c("l", "l", "l", "l", "l"))

n_rows = nrow(py$raw_rf_model_stats_df)
xt_raw_rf_model_stats = print.xtable(xt,
                      type = "latex", 
                      tabular.environment = "tabular",
                      booktabs = TRUE,
                      floating = FALSE,
                      include.rownames = FALSE,
                      include.colnames = TRUE,
                      NA.string="-",
                      comment=FALSE,
                      timestamp=FALSE,
                      add.to.row = list(pos=as.list(-1:n_rows), command=c('\\toprule ','',rep('\\midrule ',n_rows-1),'\\bottomrule\n')),
                      sanitize.colnames.function = function(x) latex_bold(x)
                      );
```
\section{Random Forest Sklearn Model}
\begin{table}[h]
\small
`r xt_raw_rf_model_stats`
\end{table}

\FloatBarrier

```{python, include = FALSE}
######## XGBOOST MODEL TABLE #############
def rf_stats(raw_data_rf, processed_data_rf):
    train_raw = raw_data_rf["train"]
    test_raw = raw_data_rf["test"]

    train_processed = processed_data_rf["train"]
    test_processed = processed_data_rf["test"]

    return pd.DataFrame(data=[
    ["raw", "auc", train_raw["auc"],  test_raw["auc"]],
    ["raw", "error", train_raw["error"],  test_raw["error"]],
    ["processed", "auc", train_processed["auc"],  test_processed["auc"]],
    ["processed", "error", train_processed["error"],  test_processed["error"]],
    ], columns=["Dataset Type", "Metric Name", "Value on Training Set", "Value on Test Set"])

xgb_model_stats_df = presenter_df(rf_stats(raw_xgb, processed_xgb))
```


```{r, include=FALSE}
######## XGBOOST MODEL DATA TABLE #############
xt = xtable(py$xgb_model_stats_df, align = c("l", "l", "l", "l", "l"))

n_rows = nrow(py$xgb_model_stats_df)
xt_xgb_model_stats = print.xtable(xt,
                      type = "latex", 
                      tabular.environment = "tabular",
                      booktabs = TRUE,
                      floating = FALSE,
                      include.rownames = FALSE,
                      include.colnames = TRUE,
                      NA.string="-",
                      comment=FALSE,
                      timestamp=FALSE,
                      add.to.row = list(pos=as.list(-1:n_rows), command=c('\\toprule ','',rep('\\midrule ',n_rows-1),'\\bottomrule\n')),
                      sanitize.colnames.function = function(x) latex_bold(x)
                      );
```
\section{XGBoost Model}
\begin{table}[h]
\small
`r xt_xgb_model_stats`
\end{table}

\clearpage


```{python, include = FALSE}
######## FIXED POINT PROTOTYPES TABLE #############
if len(fp_df) > 0:
  data = [as_prototype_dict_x(id_for_x, pt, action_set.df) for (id_for_x, pt) in zip(fp_df["id_for_x"].values, fp_df["point"].values)]


  fp_prototypes_df = presenter_df(pd.DataFrame(data=data))
  fp_prototypes_df = fp_prototypes_df.transpose()
else:
  fp_prototypes_df = presenter_df(pd.DataFrame(data=[pd.NA]))
```

```{r, include = FALSE}
######## FIXED POINT PROTOTYPES TABLE #############
xt = xtable(py$fp_prototypes_df)

n_rows = nrow(py$fp_prototypes_df)
xt_str_fp_prototypes = print.xtable(xt,
                      type = "latex", 
                      tabular.environment = "tabular",
                      booktabs = TRUE,
                      floating = FALSE,
                      include.rownames = TRUE,
                      include.colnames = FALSE,
                      NA.string="-",
                      comment=FALSE,
                      timestamp=FALSE,
                      add.to.row = list(pos=as.list(-1:n_rows), command=c('\\toprule ','',rep('\\midrule ',n_rows-1),'\\bottomrule\n')),
                      sanitize.rownames.function = function(x) latex_bold(x)
                      )

```

\small \section{Fixed Points Prototypes}
\begin{table}[h]
\resizebox{14cm}{!}{
`r xt_str_fp_prototypes`
}
\end{table}

\clearpage


```{r, include = FALSE}
######## FIXED POINT PROTOTYPES TABLE #############
xt = xtable(py$fp_prototypes_df)

n_rows = nrow(py$fp_prototypes_df)
xt_str_prototype = print.xtable(xt,
                      type = "latex", 
                      tabular.environment = "tabular",
                      booktabs = TRUE,
                      floating = FALSE,
                      include.rownames = TRUE,
                      include.colnames = FALSE,
                      NA.string="-",
                      comment=FALSE,
                      timestamp=FALSE,
                      add.to.row = list(pos=as.list(-1:n_rows), command=c('\\toprule ','',rep('\\midrule ',n_rows-1),'\\bottomrule\n')),
                      sanitize.rownames.function = function(x) latex_bold(x),
                      )

```


```{python, include = FALSE}
######## Fixed REGIONS W/O Recourse #########
    
from copy import deepcopy
fixed_regions_df = deepcopy(rs_df)
fixed_regions_df = fixed_regions_df[fixed_regions_df.num_reachable_pts > 0]
```


```{python, include=FALSE}
######## fixed regions PLOT #############
# aggregate fixed regions and count by number of reachable pts and how many x vals have fixed regions
agg_fixed_regions_df = fixed_regions_df["num_reachable_pts"].value_counts().sort_index().rename_axis('num_reachable_pts').reset_index(name='num_of_x_pts')
agg_fixed_regions_df['num_reachable_pts'] = agg_fixed_regions_df['num_reachable_pts'].astype(str)
fig_path = "/Users/avnikothari/Dropbox/Apps/Overleaf/infeasible-recourse/" + "/twitter_bot_cf.png"
```


```{R, fig.width = 7, fig.height = 4, echo = FALSE}
######## fixed regions PLOT #############

py$agg_fixed_regions_df$num_reachable_pts <- factor(py$agg_fixed_regions_df$num_reachable_pts, levels = py$agg_fixed_regions_df$num_reachable_pts)

p<-ggplot(data=py$agg_fixed_regions_df) + 
  geom_col(aes(x=num_reachable_pts, y=num_of_x_pts, fill="plum3")) +
  scale_fill_manual(values = c("plum3")) +
  labs(x="num reachable pts", y="num of x pts", title="Breakdown of Fixed Regions") +
  theme(plot.title = element_text(hjust = 0.5), text = element_text(size = 7), legend.position = "none")

# Print plots to a pdf file
png(py$fig_path)
print(p)     
dev.off() 

p
```

```{python, include=FALSE}
 ######## RECOURSE BREAKDOWN TABLE #########
if len(fixed_regions_df) > 0:
  # values where y_i = 1 and y_hat = -1
  fixed_regions_df['y_true'] = fixed_regions_df.apply(lambda row: processed_data.y[row['id_for_x']], axis = 1)
  
  
  x_values = np.array(fixed_regions_df['point'].values.tolist())
  id_for_xs = fixed_regions_df['id_for_x'].to_numpy()  
  y_true_values = fixed_regions_df['y_true'].to_numpy()  
  
  fixed_regions_df['log_reg'] = find_model.predict_all(processed_log_reg["model"], x_values, scaler = processed_log_reg["scaler"])
  fixed_regions_df['rf_sklearn'] = find_model.predict_all(processed_rf_sklearn["model"], x_values)
  fixed_regions_df['xgb'] = find_model.predict_all(processed_xgb["model"], x_values)
```


```{python, include=FALSE}
 ######## RECOURSE BREAKDOWN TABLE #########
if len(fixed_regions_df) > 0:
  FN_df = deepcopy(fixed_regions_df[fixed_regions_df["y_true"] == 1] )
  
  log_predictions = FN_df['log_reg'].to_numpy()
  neg_log_preds = []
  for id_for_x, x_val, y_true, log_pred in zip(id_for_xs, x_values, y_true_values, log_predictions):
    if log_pred == '-':
      neg_log_preds.append({'id_for_x': id_for_x, 'x_val': x_val, 'y_true': y_true, 'logistic_classification': log_pred})
      
  neg_log_preds_df = pd.DataFrame(data=neg_log_preds)    
      
  rf_predictions = FN_df['rf_sklearn'].to_numpy()
  neg_rf_preds = []
  for id_for_x, x_val, y_true, rf_pred in zip(id_for_xs, x_values, y_true_values, rf_predictions):
    if  rf_pred == '-':
      neg_rf_preds.append({'id_for_x': id_for_x, 'x_val': x_val, 'y_true': y_true, 'rf_sklearn_classification':  rf_pred,})
  
  neg_rf_preds_df = pd.DataFrame(data=neg_rf_preds)
  
  xgb_predictions = FN_df['xgb'].to_numpy()
  neg_xgb_preds = []
  for id_for_x, x_val, y_true, xgb_pred in zip(id_for_xs, x_values, y_true_values, xgb_predictions):
    if  xgb_pred == '-':
      neg_xgb_preds.append({'id_for_x': id_for_x, 'x_val': x_val, 'y_true': y_true, 'xgb_classification':  xgb_pred})
  
  neg_xgb_preds_df = pd.DataFrame(data=neg_xgb_preds)

```


```{python, include=FALSE}
 ######## RECOURSE BREAKDOWN TABLE #########
if len(fixed_regions_df) > 0:
  are_all_negs = lambda preds: set(preds) == set(["-"])
  def get_no_recourse_regions(df, model_type):
    if model_type == 'log_reg':
      model = processed_log_reg["model"]
      scaler = processed_log_reg["scaler"]
    elif model_type == 'rf_sklearn':
      model = processed_rf_sklearn["model"]
      scaler = None
    elif model_type == 'xgb':
      model = processed_xgb["model"]
      scaler = None
  
    # filter for any negative classifications with logistic regression
    neg_fixed_region_df = pd.merge(df, rs_df[['id_for_x', 'reachable_set', 'num_reachable_pts', 'action_values']], on='id_for_x', how='inner')
    # check if all reachable points for the negative classification fixed regions are negative
    r_sets = neg_fixed_region_df['reachable_set'].values.tolist()
    a_sets = neg_fixed_region_df['action_values'].values.tolist()
    x_vals = np.array(neg_fixed_region_df['x_val'].values.tolist())
    y_true_values = np.array(neg_fixed_region_df['y_true'].values.tolist())
    id_for_xs = np.array(neg_fixed_region_df['id_for_x'].values.tolist())
    num_reachable_pts = np.array(neg_fixed_region_df['num_reachable_pts'].values.tolist())
    
    no_recourse_regions = []
    for r_set, a_set, x_val, y_true, id_for_x, nrpts in zip(r_sets, a_sets, x_vals, y_true_values, id_for_xs, num_reachable_pts):
      if are_all_negs(find_model.predict_all(model, np.array(r_set) ,scaler)):
        no_recourse_regions.append({'id_for_x': id_for_x, 'x_val': x_val, 'y_true': y_true, 'action_values': a_set, 'reachable_set': r_set, 'num_reachable_pts': nrpts})
    return pd.DataFrame(data=no_recourse_regions)
  
  if len(neg_log_preds_df) > 0:
    log_reg_no_recourse_regions_df = get_no_recourse_regions(neg_log_preds_df, 'log_reg')
    FN_num_log_neg_regions = len(log_reg_no_recourse_regions_df[log_reg_no_recourse_regions_df['y_true'] == 1]) if len(log_reg_no_recourse_regions_df) > 0 else 0
    TN_num_log_neg_regions = len(log_reg_no_recourse_regions_df[log_reg_no_recourse_regions_df['y_true'] == -1]) if len(log_reg_no_recourse_regions_df) > 0 else 0
  else: 
    FN_num_log_neg_regions = 0
    TN_num_log_neg_regions = 0
  
  if len(neg_rf_preds_df) > 0:
    rf_no_recourse_regions_df = get_no_recourse_regions(neg_rf_preds_df, 'rf_sklearn')
    FN_num_rf_regions = len(rf_no_recourse_regions_df[rf_no_recourse_regions_df['y_true'] == 1]) if len(rf_no_recourse_regions_df) > 0 else 0
    TN_num_rf_regions = len(rf_no_recourse_regions_df[rf_no_recourse_regions_df['y_true'] == -1]) if len(rf_no_recourse_regions_df) > 0 else 0
  else:
    FN_num_rf_regions = 0
    TN_num_rf_regions = 0
    
  if len(neg_xgb_preds_df) > 0:
    xgb_no_recourse_regions_df = get_no_recourse_regions(neg_xgb_preds_df, 'xgb')
    FN_num_xgb_regions = len(xgb_no_recourse_regions_df[xgb_no_recourse_regions_df['y_true'] == 1]) if len(xgb_no_recourse_regions_df) > 0 else 0
    TN_num_xgb_regions = len(xgb_no_recourse_regions_df[xgb_no_recourse_regions_df['y_true'] == -1]) if len(xgb_no_recourse_regions_df) > 0 else 0
  else:
    FN_num_xgb_regions = 0
    TN_num_xgb_regions = 0
else:
  FN_num_log_neg_regions = 0
  TN_num_log_neg_regions = 0

  FN_num_rf_regions = 0
  TN_num_rf_regions = 0

  FN_num_xgb_regions = 0
  TN_num_xgb_regions = 0

```


```{python, include = FALSE}
 ######## RECOURSE BREAKDOWN TABLE #########
# y_i = 1 and y_hat = 1
reformat_prediction = lambda prediction: -1 if (prediction == "-") else 1
do_reformat = lambda x: np.array(list(map(lambda pred: reformat_prediction(pred), x)))

def get_preds(model_type):
  if model_type == 'log_reg':
    model = processed_log_reg["model"]
    scaler = processed_log_reg["scaler"]
  elif model_type == 'rf_sklearn':
    model = processed_rf_sklearn["model"]
    scaler = None
  elif model_type == 'xgb':
    model = processed_xgb["model"]
    scaler = None
    
  pred_labels = find_model.predict_all(model, processed_data.X ,scaler)
  return do_reformat(pred_labels)

LR_pred_labels = get_preds('log_reg')
RF_pred_labels = get_preds('rf_sklearn')
XGB_pred_labels = get_preds('xgb')

def get_TP(pred_labels):
  return np.sum(np.logical_and(pred_labels == 1, processed_data.y == 1))

LR_TP = get_TP(LR_pred_labels)
RF_TP = get_TP(RF_pred_labels)
XGB_TP = get_TP(XGB_pred_labels)

# y_i = 1 and y_hat = -1
def get_FN(pred_labels):
  return np.sum(np.logical_and(pred_labels == -1, processed_data.y == 1))
LR_FN = get_FN(LR_pred_labels)
RF_FN = get_FN(RF_pred_labels)
XGB_FN = get_FN(XGB_pred_labels)

# y_i = -1 and y_hat = 1
def get_FP(pred_labels):
  return np.sum(np.logical_and(pred_labels == 1, processed_data.y == -1))

LR_FP = get_FP(LR_pred_labels)
RF_FP = get_FP(RF_pred_labels)
XGB_FP = get_FP(XGB_pred_labels)

# y_i = -1 and y_hat = -1
def get_TN(pred_labels):
  return np.sum(np.logical_and(pred_labels == -1, processed_data.y == -1))

LR_TN = get_TN(LR_pred_labels)
RF_TN = get_TN(RF_pred_labels)
XGB_TN = get_TN(XGB_pred_labels)

```

```{python, include = FALSE}
 ######## RECOURSE BREAKDOWN TABLE #########
 
if len(fp_df) > 0:
  fp_df['y_true'] = fp_df.apply(lambda row: processed_data.y[row['id_for_x']], axis = 1)
  fp_df['LR'] = fp_df.apply(lambda row: float(find_model.probs(processed_log_reg['model'], row['point'], OUTCOME_PROB, scaler=processed_log_reg['scaler']).strip('%')), axis = 1)
  fp_df['RF'] = fp_df.apply(lambda row: find_model.predict(processed_rf_sklearn['model'], row['point']), axis =1 )
  fp_df['XGB'] = fp_df.apply(lambda row: find_model.predict(processed_xgb['model'], row['point']), axis =1 )
  
  FN_num_log_fp = len(fp_df[(fp_df['LR'] < 50.0) & (fp_df['y_true'] == 1)])
  TN_num_log_fp = len(fp_df[(fp_df['LR'] < 50.0) & (fp_df['y_true'] == -1)])
  
  FN_num_rf_fp = len(fp_df[(fp_df['RF'] == "-") & (fp_df['y_true'] == 1)])
  TN_num_rf_fp = len(fp_df[(fp_df['RF'] == "-") & (fp_df['y_true'] == -1)])
  
  FN_num_xgb_fp = len(fp_df[(fp_df['XGB'] == '-') & (fp_df['y_true'] == 1)])
  TN_num_xgb_fp = len(fp_df[(fp_df['XGB'] == '-') & (fp_df['y_true'] == -1)])
else:
  FN_num_log_fp = 0
  TN_num_log_fp = 0
  
  FN_num_rf_fp = 0
  TN_num_rf_fp = 0
  
  FN_num_xgb_fp = 0
  TN_num_xgb_fp = 0


```

```{python, include = FALSE}
 ######## RECOURSE BREAKDOWN TABLE #########

FN_log_no_recourse = FN_num_log_fp + FN_num_log_neg_regions
FN_rf_no_recourse = FN_num_rf_fp + FN_num_rf_regions
FN_xgb_no_recourse = FN_num_xgb_fp+  FN_num_xgb_regions

TN_log_no_recourse = TN_num_log_fp + TN_num_log_neg_regions
TN_rf_no_recourse = TN_num_rf_fp + TN_num_rf_regions
TN_xgb_no_recourse = TN_num_xgb_fp+  TN_num_xgb_regions

columns = ["y_true", "y_hat", "recourse status", "LR", "RF", "XGBoost"]
data = [
  [1, 1, 'any', LR_TP, RF_TP, XGB_TP],
  [pd.NA, pd.NA, 'has recourse', LR_TP, RF_TP, XGB_TP],
  [pd.NA, pd.NA, 'no recourse', 0, 0, 0],
  [1, -1, 'any', LR_FN, RF_FN, XGB_FN],
  [pd.NA, pd.NA, 'has recourse', LR_FN -FN_log_no_recourse, RF_FN - FN_rf_no_recourse, XGB_FN - FN_xgb_no_recourse ],
  [pd.NA, pd.NA, 'no recourse', FN_log_no_recourse , FN_rf_no_recourse , FN_xgb_no_recourse],
  [pd.NA, pd.NA, 'no recourse - fixed point', FN_num_log_fp, FN_num_rf_fp, FN_num_xgb_fp],
  [pd.NA, pd.NA, 'no recourse - fixed_region',FN_num_log_neg_regions , FN_num_rf_regions, FN_num_xgb_regions],
  [-1, 1, 'any', LR_FP, RF_FP, XGB_FP],
  [pd.NA, pd.NA, 'has recourse', LR_TP, RF_TP, XGB_TP],
  [pd.NA, pd.NA, 'no recourse', 0, 0, 0],
  [-1, -1, 'any', LR_TN, RF_TN, XGB_TN],
  [pd.NA, pd.NA, 'has recourse', LR_TN -TN_log_no_recourse, RF_TN - TN_rf_no_recourse, XGB_TN - TN_xgb_no_recourse ],
  [pd.NA, pd.NA, 'no recourse', TN_log_no_recourse , TN_rf_no_recourse , TN_xgb_no_recourse],
  [pd.NA, pd.NA, 'no recourse - fixed point', TN_num_log_fp, TN_num_rf_fp, TN_num_xgb_fp],
  [pd.NA, pd.NA, 'no recourse - fixed_region',TN_num_log_neg_regions , TN_num_rf_regions, TN_num_xgb_regions],
]

recourse_breakdown_df = pd.DataFrame(data = data, columns = columns)
recourse_breakdown_df = presenter_df(recourse_breakdown_df)
```

```{r, include = FALSE}
 ######## RECOURSE BREAKDOWN TABLE #########
 xt = xtable(py$recourse_breakdown_df)

 # print the xtable as a string
 n_rows = nrow(py$recourse_breakdown_df)
 xt_str_recourse_breakdown = print.xtable(xt,
                       type = "latex",
                       tabular.environment = "tabular",
                       booktabs = TRUE,
                       floating = FALSE,
                       include.rownames = FALSE,
                       include.colnames = TRUE,
                       NA.string=" ",
                       comment=FALSE,
                       timestamp=FALSE,
                       add.to.row = list(pos=as.list(-1:n_rows), command=c('\\toprule ','',rep('\\midrule ',n_rows-1),'\\bottomrule\n')),
                       sanitize.rownames.function = function(x) {
                         x <- paste0('{\\bfseries ', x, '}')
                         x <- gsub(fixed = TRUE, pattern = "_", replacement = "\\_",x= x)
                         return(x)
                       },
                       sanitize.colnames.function = function(x) {
                         x <- paste0('{\\bfseries ', x, '}')
                         x <- gsub(fixed = TRUE, pattern = "_", replacement = "\\_",x= x)
                         return(x)
                         }
                       );
```

\begin{table}[h]
\caption{Recourse Breakdown}
\small
`r xt_str_recourse_breakdown`
\end{table}


```{python, include = FALSE}
######## fixed REGION PROTOTYPE y_true = 1 and y_hat = -1 #########
if len(fixed_regions_df) > 0:
  if len(log_reg_no_recourse_regions_df) > 0:
    fn_fixed_region_df = log_reg_no_recourse_regions_df[log_reg_no_recourse_regions_df['y_true'] == 1]
    if (len(fn_fixed_region_df) == 0) and len(rf_no_recourse_regions_df) > 0:
      fn_fixed_region_df = rf_no_recourse_regions_df[rf_no_recourse_regions_df['y_true'] == 1]
      if (len(fn_fixed_region_df) == 0) and len(xgb_no_recourse_regions_df) > 0:
        fn_fixed_region_df = xgb_no_recourse_regions_df[xgb_no_recourse_regions_df['y_true'] == 1]
  
   
  region = fn_fixed_region_df[fn_fixed_region_df['num_reachable_pts'] > 0][0:1]
  region = pd.merge(region, rs_df[['id_for_x', 'action_values']], on='id_for_x', how='inner')
   
   # create dataframe with no recourse fixed region of a region with 3 action values
  def fixed_protos(id_for_x, x_val, action_values):
    x_proto = as_prototype_dict_x(id_for_x, x_val, action_set.df)
    acts_protos = [as_prototype_dict_action(x_val, act, action_set.df) for act in action_values]
    data = [x_proto] + acts_protos
    columns = ["x_val"] + [f"action_{i+1}" for i in range (0, len(action_values))]
    df = pd.DataFrame(data=data).transpose()
    return df.set_axis(columns, axis=1)



  fn_fixed_protos_df = fixed_protos(region["id_for_x"].values[0], region["x_val"].values[0], region["action_values_y"].values[0])
  fn_fixed_protos_df = presenter_df(fn_fixed_protos_df)

else:
  fn_fixed_protos_df = presenter_df(pd.DataFrame(data=[pd.NA]))
  

```

```{r, include = FALSE}
######## fixed REGION PROTOTYPE y_true = 1 and y_hat = -1 #########
 xt = xtable(py$fn_fixed_protos_df)

 # print the xtable as a string
 n_rows = nrow(py$fn_fixed_protos_df)
 xt_str_fn_fixed_protos = print.xtable(xt,
                       type = "latex",
                       tabular.environment = "tabular",
                       booktabs = TRUE,
                       floating = FALSE,
                       include.rownames = TRUE,
                       include.colnames = TRUE,
                       NA.string=" ",
                       comment=FALSE,
                       timestamp=FALSE,
                       add.to.row = list(pos=as.list(-1:n_rows), command=c('\\toprule ','',rep('\\midrule ',n_rows-1),'\\bottomrule\n')),
                       sanitize.rownames.function = function(x) {
                         x <- paste0('{\\bfseries ', x, '}')
                         x <- gsub(fixed = TRUE, pattern = "_", replacement = "\\_",x= x)
                         return(x)
                       },
                       sanitize.colnames.function = function(x) {
                         x <- paste0('{\\bfseries ', x, '}')
                         x <- gsub(fixed = TRUE, pattern = "_", replacement = "\\_",x= x)
                         return(x)
                         }
                       );
```

\begin{table}[h]
\caption{fixed Region Prototype. $y\_true = 1, y\_hat = -1$}
\small
`r xt_str_fn_fixed_protos`
\end{table}














